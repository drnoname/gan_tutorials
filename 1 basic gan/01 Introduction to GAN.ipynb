{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to GAN\n",
    "\n",
    "In Week 1, you will learn the fundamental components of GANs and build a basic GAN using PyTorch (your first GAN, perhaps!). By the end of Week 2, you will have used convolutional layers to build an advanced DCGAN that processes images. In Week 3, you will learn about mode collapse and apply W-Loss and gradient penalties to remedy it. Finally, you will learn how to effectively control your GANs and build conditional GANs in Week 4.\n",
    "\n",
    "- Week 1: Intro to GANs\n",
    "- Week 2: Deep Convolutional GANs\n",
    "- Week 3: Wasserstein GANs with Gradient Penalty\n",
    "- Week 4: Conditional GAN & Controllable Generation\n",
    "\n",
    "打个比喻，一个GAN 是两个networks，一个是art forger，一个是art inspector\n",
    "\n",
    "- art forger who's trying to mimick pieces of art or realistic artworks. \n",
    "- Then there's an art inspector who's looking at a pile of real famous art and also this fake art that's forged by this art forger, and trying to figure out which ones are real and which ones are fake and giving that feedback back to the art forger to improve over time.\n",
    "\n",
    "IKEA effect: you like your furniture more if you build it yourself.\n",
    "\n",
    "GAN is an unsupervised technique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generative Models\n",
    "\n",
    "### 1.1 Discriminative Models v.s. Generative Models\n",
    "\n",
    "discriminative models distinguish between classes, generative models learn to produce realistic examples.\n",
    "\n",
    "- Discriminative models 通常是作分类器。给一个feature vector **x**，计算p(y|**x**), 输出最可能的class y.\n",
    "\n",
    "- Generative models 的目标是learn realistic representation of some class. \n",
    "    - 通常，输入一个class y + noise，输出feature **x**.\n",
    "    - Noise: 确保每次生成的dog 都不一样。\n",
    "\n",
    "### 1.2 Popular Generative Models\n",
    "\n",
    "#### Variational AutoEncoder (VAE)\n",
    "\n",
    "VAE 是由两个network 组成，一个encoder，一个decoder。\n",
    "- encoder: 在latent space 中找到对原始image 比较好的一个representation.\n",
    "- decoder: reconstruct image\n",
    "\n",
    "<img src=\"figures/vae.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "\n",
    "当decoder 训练好了，我们可以从latent space 中随机选一个点作为decoder 的输入，然后decoder 会输出一个图片。\n",
    "\n",
    "上面讲的是一个autoencoder 的部分。variational 是指，encoder 对于一个输入，不会map 到latent space 上的一个点，而是一个distribution，然后通过sample 获取一个点。\n",
    "\n",
    "#### Generative Adversarial Networks (GAN)\n",
    "GAN 有两个network play against each other (this is why it is called adversarial).\n",
    "\n",
    "- Generator: 类似与VAE 中的decoder \n",
    "- Discriminator: 区分fake 和real \n",
    "\n",
    "<img src=\"figures/gan.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "一开始，generator 生成的图片和真实的图片差很远，所以很弱。对于discriminator，区分这样的图片很简单，所以discriminator 也很弱。随着训练的进行，Generator 会产生质量更高的图片，要区分这样的图片，对与discriminator 的要求也越高。所以discriminator 也会越来越强。训练后，我们不再需要discriminator，直接给generator 一些random noise，就会生成一个质量很高的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Real Life GANs\n",
    "\n",
    "### 2.1 GAN Applications\n",
    "\n",
    "#### 图像生成\n",
    "\n",
    "下面这个网站可以看生成的人像。\n",
    "https://www.thispersondoesnotexist.com/\n",
    "\n",
    "#### style transfer\n",
    "\n",
    "马 -> 斑马\n",
    "\n",
    "#### image translation\n",
    "\n",
    "<img src=\"figures/gan_draw.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "#### Other applications\n",
    "\n",
    "<img src=\"figures/gan_application.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "\n",
    "\n",
    "### 2.2 Major Companies\n",
    "\n",
    "Adobe: next gen photoshop\n",
    "IBM: data augmentation\n",
    "Google: Text Generation\n",
    "Disney: Super Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Intuition Behind GANs\n",
    "\n",
    "### 3.1 The goal of geneator and discriminator\n",
    "\n",
    "- generator: \n",
    "the generator forges fake images to try to look as realistic as possible, and it does this in the hopes of fooling the discriminator. generator 看不到real pictures。\n",
    "\n",
    "- discriminator: to tell the generator's fakes apart from real examples that you give it.\n",
    "\n",
    "generator 和discriminator compete with each other。最终，fake 看上去和real 差不多。\n",
    "\n",
    "你需要real pictures 作为训练的输入。\n",
    "\n",
    "\n",
    "### 3.2 The competition between them\n",
    "\n",
    "<img src=\"figures/competition.png\" alt=\"drawing\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Discriminator\n",
    "\n",
    "下面，我们介绍discriminator. Discriminator 实际上是一个classifier，一个classifier 实际上是给出一个条件概率。Given input features X, what is the probability distribution of different classes Y.\n",
    "\n",
    "<img src=\"figures/classifier_prob.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "\n",
    "<img src=\"figures/discriminator.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "<img src=\"figures/discriminator_prob.png\" alt=\"drawing\" width=\"300\"/>\n",
    "\n",
    "The probability (0.85) will be given to the generator as feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generator\n",
    "\n",
    "To model the probability of features x conditioned on a class y.\n",
    "\n",
    "#### Learning\n",
    "\n",
    "<img src=\"figures/generator_learning.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "\n",
    "#### Sampling\n",
    "\n",
    "<img src=\"figures/generator_sampling.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "the generator's job is just to model how cats are in the natural world.\n",
    "the most common cat will have more chances to be generated, while the less common ones will be produced much more rarely. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Binary Classs Entropy (BCE) Function\n",
    "\n",
    "$$-\\frac{1}{m}\\sum^m_{i=1} [y^{(i)}log\\hat{y}^{(i)} + (1-y^{(i)})log(1 - \\hat{y}^{(i)}) ]$$\n",
    "\n",
    "其中，$\\hat{y}^{(i)} = h(x^{(i)}, \\theta)$ paramitized by $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Put It All Together\n",
    "\n",
    "需要注意的一个点是，generator 和discriminator 应该同时被训练（both model should be improved together）。\n",
    "- 如果有一个超级discriminator 和一个比较弱的generator，所有生成的图片100%的都会被标记为fake，这时候genertor 没办法知道自己将如何改进来成功欺骗discriminator（缺少成功案例）。100% is not useful for the generator at all because it doesn't know which way to grow and learn. \n",
    "- 如果有一个超级generator 和一个比较弱的discriminator，所有生成的图片100%的都会被标记为real，这时候discriminator 也没有办法知道该如何改进(no way to improve)。\n",
    "\n",
    "然而，discriminator 的工作是相对简单的，所以通常训练GAN 遇到的一个问题是：having superior discriminator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] [Hyperspherical Variational Auto-Encoders](https://arxiv.org/abs/1804.00891)\n",
    "\n",
    "[2] https://colab.research.google.com/github/https-deeplearning-ai/GANs-Public/blob/master/C1W1_(Colab)_Pre_trained_model_exploration.ipynb\n",
    "\n",
    "[3] http://thesecatsdonotexist.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
